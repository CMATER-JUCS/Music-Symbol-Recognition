{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "homus.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtPNTOdraOvj"
      },
      "source": [
        "# Handwritten Music Symbol Recognition with Deep Ensemble\n",
        "\n",
        "In ancient times, there was no system to record or document the music. Later, the musical pieces from the classical and post-classical period of European music were documented as scores using western staff notations. These notations are used by most of the modern genres of music due to its versatility. Hence, it is very important to develop a method that can store such sheets of handwritten music scores digitally. Optical Music Recognition (OMR) is a system which automatically interprets the scanned handwritten music scores. In this work, we have proposed a classifier ensemble of deep transfer learning models with Support Vector Machine (SVM) as the aggregation function for handwritten music symbol recognition. We have applied three pre-trained deep learning models, namely ResNet50, GoogleNet and DenseNet161 (each trained on ImageNet) and fine-tuned on our target datasets i.e., music symbol image datasets. The proposed ensemble is able to capture a more complex association of the base learners, thus improving the overall performance. We have evaluated the proposed model on three publicly available standard datasets, namely Handwritten Online Music Symbols (HOMUS), Capitan_Score_Non-uniform and Rebelo_real,and achieved state-of-the-art results for all three datasets.\n",
        "<br></br>\n",
        "Hyperparameter Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "bB6FBokCaOvl"
      },
      "source": [
        "#hyper params\n",
        "lr = 1e-4\n",
        "bs = 32\n",
        "val_split = 0.85\n",
        "num_epoch = 20\n",
        "num_classes = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD3SYCYFaOvm"
      },
      "source": [
        "We use pytorch to implement the project. Here we include relevant modules and check for GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "baTIw89naOvm"
      },
      "source": [
        "#imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from  numpy import exp,absolute\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "from sklearn import svm\n",
        "import sklearn.model_selection as model_selection\n",
        "from sklearn.metrics import accuracy_score,f1_score,precision_score ,recall_score \n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExGEDRnFaOvm"
      },
      "source": [
        "This function gives us training, validation and test set and takes the path to folder as input. This folder must be arranged as per `torchvision.datasets.Imagefolder` specification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Brbosm-BaOvn"
      },
      "source": [
        "def get_TVT(path):\n",
        "    data_transforms = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.ImageFolder(path+'train/',transform=data_transforms)\n",
        "\n",
        "    train_size = math.floor(len(dataset)*val_split)\n",
        "    val_size = len(dataset) - train_size\n",
        "    trainset, valset = data.random_split(dataset,lengths=[train_size,val_size])\n",
        "    testset = datasets.ImageFolder(path+'test/',transform=data_transforms)\n",
        "    return trainset,valset,testset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrwnsEF2aOvn"
      },
      "source": [
        "This is the function to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "muCobMSmaOvn"
      },
      "source": [
        "def train_model(trainset, valset, model, criterion, optimizer, scheduler, num_epochs):\n",
        "    dataloaders = {\n",
        "        'train': data.DataLoader(trainset,batch_size=bs,shuffle=True),\n",
        "        'val' : data.DataLoader(valset,batch_size=bs,shuffle=True)\n",
        "    }\n",
        "    dataset_sizes = {'train':len(trainset),'val':len(valset)}\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # print('bruh')\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1) \n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhTwa0hlaOvp"
      },
      "source": [
        "This function calculates the model accuracy on test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "f3xEkGmuaOvp"
      },
      "source": [
        "def test_acc(model, testset):\n",
        "    running_corrects = 0\n",
        "    testloader = data.DataLoader(testset,batch_size=bs,shuffle=True)\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "    return (running_corrects/len(testset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "143T9nlcaOvq"
      },
      "source": [
        "This function returns a pair of set of data X and label Y. The elements in X represent the concatenated score from the models. If size of dataset is N, number of classes is c and number of trained model is k then the shape of X is (N,ck). The samples are also given weight based on total number of unique classification made on them (Explained later)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_H-cCfZraOvq"
      },
      "source": [
        "def get_weighted_score_ft(models,dataset):\n",
        "    num_models = len(models)\n",
        "    X = np.empty((0,num_models*num_classes))\n",
        "    Y = np.empty((0),dtype=int)\n",
        "    dataloader = data.DataLoader(dataset,batch_size=1,shuffle=True)\n",
        "    for inputs,labels in dataloader:\n",
        "        inputs,labels = inputs.to(device),labels.to(device)\n",
        "        predictions = set()\n",
        "        with torch.set_grad_enabled(False):\n",
        "            x = models[0](inputs)\n",
        "            _, preds = torch.max(x, 1)\n",
        "            predictions.add(preds)\n",
        "            for i in range(1,num_models):\n",
        "                x1 = models[i](inputs)\n",
        "                _, preds = torch.max(x1, 1)\n",
        "                predictions.add(preds)\n",
        "                x = torch.cat((x,x1),dim=1)\n",
        "            if len(predictions) > 1:\n",
        "                X = np.append(X,x.cpu().numpy()*3,axis=0)\n",
        "            else:\n",
        "                X = np.append(X,x.cpu().numpy(),axis=0)\n",
        "            Y = np.append(Y,labels.cpu().numpy(),axis=0)     \n",
        "    return X,Y\n",
        "def get_score_ft(models,dataset):\n",
        "    num_models = len(models)\n",
        "    X = np.empty((0,num_classes))\n",
        "    j = np.empty((0,num_models*num_classes))\n",
        "    Y = np.empty((0),dtype=int)\n",
        "    dataloader = data.DataLoader(dataset,batch_size=bs,shuffle=True)\n",
        "    for inputs,labels in dataloader:\n",
        "        inputs,labels = inputs.to(device),labels.to(device)\n",
        "        with torch.set_grad_enabled(False):\n",
        "            x = models[0](inputs)\n",
        "            for i in range(1,num_models):\n",
        "                x = torch.cat((x,models[i](inputs)),dim=1)\n",
        "            \n",
        "            if(x.shape[0] != bs): break\n",
        "            j = np.append(X,x.cpu().numpy(),axis=0)\n",
        "            X = np.append(X,x.cpu().numpy(),axis=0)\n",
        "            Y = np.append(Y,labels.cpu().numpy(),axis=0)\n",
        "    return X,Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poI5HMBDaOvq"
      },
      "source": [
        "We load the models with pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "gXrt81V6aOvq"
      },
      "source": [
        "def get_models():\n",
        "    googlenet = torchvision.models.googlenet(pretrained=True)\n",
        "    resnet = torchvision.models.resnet50(pretrained=True)\n",
        "    densenet = torchvision.models.densenet161(pretrained=True)\n",
        "\n",
        "    densenet.classifier = nn.Linear(2208,num_classes)\n",
        "    resnet.fc = nn.Linear(2048,num_classes)\n",
        "    googlenet.fc = nn.Linear(1024,num_classes)\n",
        "    densenet = densenet.to(device)\n",
        "    resnet = resnet.to(device)\n",
        "    googlenet = googlenet.to(device)\n",
        "\n",
        "    return [densenet,googlenet,resnet]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRU5AmB-aOvr"
      },
      "source": [
        "This is the main code cell where all the functions are utilised together. Now let us consider there are $K$ number of base classifiers $\\{CF_1, CF_2, \\dots, CF_K\\}$ to deal with an $n$-class classification problem. Hence, the output of any classifier (say, $CF_i$) is an $n$-dimensional vector $O_i = {s_1^i, s_2^i, \\dots, s_n^i}$. Here, $s_j^i$ is confidence score produced by $i_{th}$ classifier for the $j_{th}$ class. We concatenate all the output vectors produced by the classifiers $\\{CF_1, CF_2, \\dots, CF_K\\}$ to get a vector $S$ of length $nK$. $S$ is represented by\n",
        "\n",
        "\\begin{equation}\n",
        "    \\label{equ:final_vector}\n",
        "    S = \\{s_1^1, s_1^2, \\dots, s_2^1, s_2^2, \\dots, s_n^K\\}\n",
        "\\end{equation}\n",
        "\n",
        "One such vector $S$ is produced for every sample of the dataset. Let us consider that we have $N$ such samples with corresponding labels $y_i$ in the dataset to be used for training. Thus obtained the set $\\{(S_1, y_1), (S_2, y_2),\\\\ \\dots, (S_N, y_N)\\}$ on which we train the SVM model. To introduce weights on samples, we consider the total number of unique predictions made on a sample by the base classifiers. For example, if there are three base classifiers and for some sample two of the classifiers are predicting the label 'class-x' and the remaining one is predicting the label 'class-y', then the total number of unique predictions of that sample is $2$. If the total number of prediction is greater than $1$, it suggests that there is a conflict among the classifiers on the correct class. So we propose that the SVM must put more emphasis on these samples in order to approximate a better decision boundary or support vectors.\n",
        "\n",
        "A sample is assigned with $\\mathcal{W}$ times more weight if the number of unique predictions regarding the corresponding image is greater than $\\lambda$, which is an integer and whose value lies between $[1, K]$. In this work, we choose the values of both $K$ and $\\lambda$ to be 3. The value of $\\mathcal{W}$ is taken as 3 which is decided experimentally.\n",
        "\n",
        "While testing and image it is first passed through all of the three DL models and the three output vectors are obtained. Then these output vectors are concatenated, during this concatenation the order of the models are maintained (as same as during training). We pass this vector through the trained SVM classifier, which predicts the final class of our test image.\n",
        "\n",
        "![pipeline](https://user-images.githubusercontent.com/31564734/121711632-71825880-caf8-11eb-912b-1d6a147e81a1.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cMn7orQ8aOvr"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "ensemble_accuracy=[]\n",
        "for fold in ['Fold_1','Fold_2','Fold_3','Fold_4','Fold_5']:\n",
        "    for folder in  ['HOMUS']: #['Capitan_Score_Non-uniform','Capitan_Score_Uniform','Fornes_Music_Symbols_labelled']['Rebelo_Syn_labelled']:\n",
        "        trainset,valset,testset = get_TVT('/content/homus/'+fold+'/',folder)\n",
        "        models = get_models()\n",
        "        for model in models:\n",
        "            optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "            exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=9, gamma=0.1)\n",
        "            model = train_model(trainset, valset, model, criterion, optimizer, exp_lr_scheduler,num_epoch)\n",
        "\n",
        "            print(test_acc(model,testset))\n",
        "    train_X, train_Y = get_weighted_score_ft(models,trainset)\n",
        "    test_X, test_Y = get_score_ft(models,testset)\n",
        "    clf = svm.SVC(kernel='rbf',break_ties=True).fit(train_X, train_Y)\n",
        "    pred = clf.predict(test_X)\n",
        "    acc = accuracy_score(test_Y, pred)\n",
        "    ensemble_accuracy.append(acc)\n",
        "    print('Ensemble on '+fold+': '+str(acc))\n",
        "print(\"Average Ensemble Accuracy:\",sum(ensemble_accuracy)/len(ensemble_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
